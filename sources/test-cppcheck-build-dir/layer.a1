<?xml version="1.0"?>
<analyzerinfo checksum="135476295">
        <error id="noExplicitConstructor" severity="style" msg="Class &apos;dropoutLayer&apos; has a constructor with 1 argument that is not explicit." verbose="Class &apos;dropoutLayer&apos; has a constructor with 1 argument that is not explicit. Such constructors should in general be explicit for type safety reasons. Using the explicit keyword in the constructor means some mistakes when using the class can be avoided." cwe="398">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/dropoutLayer.h" line="43" column="3"/>
            <symbol>dropoutLayer</symbol>
        </error>
        <error id="missingOverride" severity="style" msg="The function &apos;checkInput&apos; overrides a function in a base class but is not marked with a &apos;override&apos; specifier." verbose="The function &apos;checkInput&apos; overrides a function in a base class but is not marked with a &apos;override&apos; specifier.">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/batchNormalizationLayer.h" line="57" column="8" info="Function in derived class"/>
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.h" line="63" column="16" info="Virtual function in base class"/>
            <symbol>checkInput</symbol>
        </error>
        <error id="shadowFunction" severity="style" msg="Local variable &apos;output&apos; shadows outer function" verbose="Local variable &apos;output&apos; shadows outer function" cwe="398">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/inputLayer.h" line="171" column="16" info="Shadow variable"/>
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/inputLayer.h" line="113" column="17" info="Shadowed declaration"/>
            <symbol>output</symbol>
        </error>
        <error id="shadowFunction" severity="style" msg="Local variable &apos;output&apos; shadows outer function" verbose="Local variable &apos;output&apos; shadows outer function" cwe="398">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/denseLayer.h" line="178" column="16" info="Shadow variable"/>
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/denseLayer.h" line="136" column="17" info="Shadowed declaration"/>
            <symbol>output</symbol>
        </error>
        <error id="shadowFunction" severity="style" msg="Local variable &apos;output&apos; shadows outer function" verbose="Local variable &apos;output&apos; shadows outer function" cwe="398">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/dropoutLayer.h" line="159" column="16" info="Shadow variable"/>
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/dropoutLayer.h" line="124" column="17" info="Shadowed declaration"/>
            <symbol>output</symbol>
        </error>
        <error id="shadowFunction" severity="style" msg="Local variable &apos;output&apos; shadows outer function" verbose="Local variable &apos;output&apos; shadows outer function" cwe="398">
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/batchNormalizationLayer.h" line="157" column="16" info="Shadow variable"/>
            <location file0="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/layer.cpp" file="/home/dante/dev/NilDa/sources/core/neuralNetwork/layers/batchNormalizationLayer.h" line="121" column="17" info="Shadowed declaration"/>
            <symbol>output</symbol>
        </error>
  <FileInfo check="CheckUnusedFunctions">
    <functiondecl functionName="getLayerName" lineNumber="18"/>
    <functiondecl functionName="createLayer" lineNumber="55"/>
    <functioncall functionName="abort"/>
    <functioncall functionName="assert"/>
    <functioncall functionName="batchNormalization"/>
    <functioncall functionName="batchNormalizationLayer"/>
    <functioncall functionName="const"/>
    <functioncall functionName="conv2D"/>
    <functioncall functionName="conv2DDimensions"/>
    <functioncall functionName="conv2DLayer"/>
    <functioncall functionName="default"/>
    <functioncall functionName="delete"/>
    <functioncall functionName="dense"/>
    <functioncall functionName="denseLayer"/>
    <functioncall functionName="dropout"/>
    <functioncall functionName="dropoutLayer"/>
    <functioncall functionName="false"/>
    <functioncall functionName="getLayerName"/>
    <functioncall functionName="identity"/>
    <functioncall functionName="if"/>
    <functioncall functionName="input"/>
    <functioncall functionName="inputLayer"/>
    <functioncall functionName="layerCode"/>
    <functioncall functionName="maxPool2D"/>
    <functioncall functionName="maxPool2DLayer"/>
    <functioncall functionName="none"/>
    <functioncall functionName="override"/>
    <functioncall functionName="pool2DDimensions"/>
    <functioncall functionName="relu"/>
    <functioncall functionName="sigmoid"/>
    <functioncall functionName="size"/>
    <functioncall functionName="softmax"/>
    <functioncall functionName="static_cast"/>
    <functioncall functionName="tanh"/>
    <functioncall functionName="type_"/>
    <functioncall functionName="useBatchNormalization"/>
  </FileInfo>
</analyzerinfo>
